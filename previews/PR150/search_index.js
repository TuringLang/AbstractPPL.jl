var documenterSearchIndex = {"docs":
[{"location":"pplapi/#Probabilistic-programming-API","page":"Probabilistic programming API","title":"Probabilistic programming API","text":"","category":"section"},{"location":"pplapi/#Abstract-model-functions","page":"Probabilistic programming API","title":"Abstract model functions","text":"","category":"section"},{"location":"pplapi/#Abstract-traces","page":"Probabilistic programming API","title":"Abstract traces","text":"","category":"section"},{"location":"pplapi/#AbstractPPL.AbstractProbabilisticProgram","page":"Probabilistic programming API","title":"AbstractPPL.AbstractProbabilisticProgram","text":"AbstractProbabilisticProgram\n\nCommon base type for models expressed as probabilistic programs.\n\n\n\n\n\n","category":"type"},{"location":"pplapi/#AbstractPPL.condition","page":"Probabilistic programming API","title":"AbstractPPL.condition","text":"condition(model, observations)\n\nCondition the generative model model on some observed data, creating a new model of the (possibly unnormalized) posterior distribution over them.\n\nobservations can be of any supported internal trace type, or a fixed probability expression.\n\nThe invariant \n\nm = decondition(condition(m, obs))\n\nshould hold for generative models m and arbitrary obs.\n\n\n\n\n\n","category":"function"},{"location":"pplapi/#AbstractPPL.decondition","page":"Probabilistic programming API","title":"AbstractPPL.decondition","text":"decondition(conditioned_model)\n\nRemove the conditioning (i.e., observation data) from conditioned_model, turning it into a generative model over prior and observed variables.\n\nThe invariant \n\nm == condition(decondition(m), obs)\n\nshould hold for models m with conditioned variables obs.\n\n\n\n\n\n","category":"function"},{"location":"pplapi/#AbstractPPL.fix","page":"Probabilistic programming API","title":"AbstractPPL.fix","text":"fix(model, params)\n\nFix the values of parameters specified in params within the probabilistic model model.  This operation is equivalent to treating the fixed parameters as being drawn from a point mass  distribution centered at the values specified in params. Thus these parameters no longer contribute to the accumulated log density. \n\nConceptually, this is similar to Pearl's do-operator in causal inference, where we intervene  on variables by setting them to specific values, effectively cutting off their dependencies  on their usual causes in the model.\n\nThe invariant\n\nm == unfix(fix(m, params))\n\nshould hold for any model m and parameters params.\n\n\n\n\n\n","category":"function"},{"location":"pplapi/#AbstractPPL.unfix","page":"Probabilistic programming API","title":"AbstractPPL.unfix","text":"unfix(model)\n\nRemove any fixed parameters from the model model, returning a new model without the fixed parameters.\n\nThis function reverses the effect of fix by removing parameter constraints that were previously set. It returns a new model where all previously fixed parameters are allowed to vary according to their  original distributions in the model.\n\nThe invariant\n\nm == unfix(fix(m, params))\n\nshould hold for any model m and parameters params.\n\n\n\n\n\n","category":"function"},{"location":"pplapi/#DensityInterface.logdensityof","page":"Probabilistic programming API","title":"DensityInterface.logdensityof","text":"logdensityof(model, trace)\n\nEvaluate the (possibly unnormalized) density of the model specified by the probabilistic program in model, at specific values for the random variables given through trace.\n\ntrace can be of any supported internal trace type, or a fixed probability expression.\n\nlogdensityof should interact with conditioning and deconditioning in the way required by probability theory.\n\n\n\n\n\n","category":"function"},{"location":"pplapi/#AbstractPPL.AbstractContext","page":"Probabilistic programming API","title":"AbstractPPL.AbstractContext","text":"AbstractContext\n\nCommon base type for evaluation contexts.\n\n\n\n\n\n","category":"type"},{"location":"pplapi/#AbstractPPL.evaluate!!","page":"Probabilistic programming API","title":"AbstractPPL.evaluate!!","text":"evaluate!!\n\nGeneral API for model operations, e.g. prior evaluation, log density, log joint etc.\n\n\n\n\n\n","category":"function"},{"location":"pplapi/#AbstractPPL.AbstractModelTrace","page":"Probabilistic programming API","title":"AbstractPPL.AbstractModelTrace","text":"AbstractModelTrace\n\nCommon base class for various trace or \"variable info\" types.\n\n\n\n\n\n","category":"type"},{"location":"interface/#Interface-(outdated)","page":"Interface (outdated)","title":"Interface (outdated)","text":"The original goal of AbstractPPL.jl was to provide a common interface for probabilistic programming. This should facilitate reuse of functions in modelling languages, to allow end users to handle models in a consistent way, and to simplify interaction between different languages and sampler implementations, from very rich, dynamic languages like Turing.jl to highly constrained or simplified models such as GPs, GLMs, or plain log-density problems.\n\nWhilst its current implementation does not do this, there are certain desiderata for such an interface, which are outlined in this page.\n\ndanger: Danger\nPlease note that this page reflects a discussion as of several years ago, and the implementation of DynamicPPL.jl has evolved not totally in sync with the ideas presented here. This page should be considered more aspirational rather than an accurate reflection of the current DynamicPPL.jl codebase.","category":"section"},{"location":"interface/#AbstractProbabilisticProgram-interface-(still-somewhat-drafty)","page":"Interface (outdated)","title":"AbstractProbabilisticProgram interface (still somewhat drafty)","text":"There are at least two somewhat incompatible conventions used for the term \"model\". None of this is particularly exact, but:\n\nIn Turing.jl, if you write down a @model function and call it on arguments, you get a model object paired with (a possibly empty set of) observations. This can be treated as instantiated \"conditioned\" object with fixed values for parameters and observations.\nIn Soss.jl, \"model\" is used for a symbolic \"generative\" object from which concrete functions, such as densities and sampling functions, can be derived, and which you can later condition on (and in turn get a conditional density etc.).\n\nRelevant discussions: 1, 2.","category":"section"},{"location":"interface/#TL/DR:","page":"Interface (outdated)","title":"TL/DR:","text":"There are three interrelating aspects that this interface intends to standardize:\n\nDensity calculation\nSampling\n\"Conversions\" between different conditionings of models\n\nTherefore, the interface consists of an AbstractProbabilisticProgram supertype, together with functions\n\ncondition(::Model, ::Trace) -> ConditionedModel\ndecondition(::ConditionedModel) -> GenerativeModel\nsample(::Model, ::Sampler = Exact(), [Int]) (from AbstractMCMC.sample)\nlogdensityof(::Model, ::Trace) and densityof(::Model, ::Trace) (from DensityInterface.jl)","category":"section"},{"location":"interface/#Traces-and-probability-expressions","page":"Interface (outdated)","title":"Traces and probability expressions","text":"First, an infrastructural requirement which we will need below to write things out.\n\nThe kinds of models we consider are, at least in a theoretical sense, distributions over traces â€“ types which carry collections of values together with their names. Existing realizations of these are VarInfo in Turing.jl, choice maps in Gen.jl, and the usage of named tuples in Soss.jl.\n\nTraces solve the problem of having to name random variables in function calls, and in samples from models. In essence, every concrete trace type will just be a fancy kind of dictionary from variable names (ideally, VarNames) to values.\n\nSince we have to use this kind of mapping a lot in the specification of the interface, let's for now just choose some arbitrary macro-like syntax like the following:\n\n@T(Y[1] = â€¦, Z = â€¦)\n\nSome more ideas for this kind of object can be found at the end.","category":"section"},{"location":"interface/#\"Conversions\"","page":"Interface (outdated)","title":"\"Conversions\"","text":"The purpose of this part is to provide common names for how we want a model instance to be understood. As we have seen, in some modelling languages, model instances are primarily generative, with some parameters fixed, while other instance types pair model instances conditioned on observations. What I call \"conversions\" here is just an interface to transform between these two views and unify the involved objects under one language.\n\nLet's start from a generative model with parameter Î¼:\n\n# (hypothetical) generative spec a la Soss\n@generative_model function foo_gen(Î¼)\n    X ~ Normal(0, Î¼)\n    Y[1] ~ Normal(X)\n    return Y[2] ~ Normal(X + 1)\nend\n\nApplying the \"constructor\" foo_gen now means to fix the parameter, and should return a concrete object of the generative type:\n\ng = foo_gen(; Î¼=â€¦)::SomeGenerativeModel\n\nWith this kind of object, we should be able to sample and calculate joint log-densities from, i.e., over the combined trace space of X, Y[1], and Y[2] â€“ either directly, or by deriving the respective functions (e.g., by converting form a symbolic representation).\n\nFor model types that contain enough structural information, it should then be possible to condition on observed values and obtain a conditioned model:\n\ncondition(g, @T(Y = â€¦))::SomeConditionedModel\n\nFor this operation, there will probably exist syntactic sugar in the form of\n\ng | @T(Y = â€¦)\n\nNow, if we start from a Turing.jl-like model instead, with the \"observation part\" already specified, we have a situation like this, with the observations Y fixed in the instantiation:\n\n# conditioned spec a la DynamicPPL\n@model function foo(Y, Î¼)\n    X ~ Normal(0, Î¼)\n    Y[1] ~ Normal(X)\n    return Y[2] ~ Normal(X + 1)\nend\n\nm = foo(; Y=â€¦, Î¼=â€¦)::SomeConditionedModel\n\nFrom this we can, if supported, go back to the generative form via decondition, and back via condition:\n\ndecondition(m) == g::SomeGenerativeModel\nm == condition(g, @T(Y = â€¦))\n\n(with equality in distribution).\n\nIn the case of Turing.jl, the object m would at the same time contain the information about the generative and posterior distribution condition and decondition can simply return different kinds of \"tagged\" model types which put the model specification into a certain context.\n\nSoss.jl pretty much already works like the examples above, with one model object being either a JointModel or a ConditionedModel, and the | syntax just being sugar for the latter.\n\nA hypothetical DensityModel, or something like the types from LogDensityProblems.jl, would be a case for a model type that does not support the structural operations condition and decondition.\n\nThe invariances between these operations should follow normal rules of probability theory. Not all methods or directions need to be supported for every modelling language; in this case, a MethodError or some other runtime error should be raised.\n\nThere is no strict requirement for generative models and conditioned models to have different types or be tagged with variable names etc. This is a choice to be made by the concrete implementation.\n\nDecomposing models into prior and observation distributions is not yet specified; the former is rather easy, since it is only a marginal of the generative distribution, while the latter requires more structural information. Perhaps both can be generalized under the query function I discuss at the end.","category":"section"},{"location":"interface/#Sampling","page":"Interface (outdated)","title":"Sampling","text":"Sampling in this case refers to producing values from the distribution specified in a model instance, either following the distribution exactly, or approximating it through a Monte Carlo algorithm.\n\nAll sampleable model instances are assumed to implement the AbstractMCMC interface. The most important aspect is sample, though, which plays the role of rand for distributions.\n\nThe results of sample generalize rand â€“ while rand(d, N) is assumed to give you iid samples, sample(m, sampler, N) returns a sample from a sequence (known as chain in the case of MCMC) of length N approximating m's distribution by a specific sampling algorithm (which of course subsumes the case that m can be sampled from exactly, in which case the \"chain\" actually is iid).\n\nDepending on which kind of sampling is supported, several methods may be supported. In the case of a (posterior) conditioned model with no known sampling procedure, we just have what is given through AbstractMCMC:\n\nsample([rng], m, N, sampler; [args]) # chain of length N using `sampler`\n\nIn the case of a generative model, or a posterior model with exact solution, we can have some more methods without the need to specify a sampler:\n\nsample([rng], m; [args])    # one random sample\nsample([rng], m, N; [args]) # N iid samples; equivalent to `rand` in certain cases\n\nIt should be possible to implement this by a special sampler, say, Exact (name still to be discussed), that can then also be reused for generative sampling:\n\nstep(g, spl = Exact(), state = nothing) # IID sample from exact distribution with trivial state\nsample(g, Exact(), [N]) \n\nwith dispatch failing for models types for which exact sampling is not possible (or not implemented).\n\nThis could even be useful for Monte Carlo methods not being based on Markov chains, e.g., particle-based sampling using a return type with weights, or rejection sampling.\n\nNot all variants need to be supported â€“ for example, a posterior model might not support sample(m) when exact sampling is not possible, only sample(m, N, alg) for Markov chains.\n\nrand is then just a special case when \"trivial\" exact sampling works for a model, e.g. a joint model.","category":"section"},{"location":"interface/#Density-Evaluation","page":"Interface (outdated)","title":"Density Evaluation","text":"danger: Danger\nNote that DensityInterface.jl has not had any substantial updates since 2021. As such, this section should be considered in a more general sense without ties to any particular package. DynamicPPL.jl does not make use of DensityInterface.jl; instead, DynamicPPL currently uses the interface specified by LogDensityProblems.jl.\n\nSince the different \"versions\" of how a model is to be understood as generative or conditioned are to be expressed in the type or dispatch they support, there should be no need for separate functions logjoint, loglikelihood, etc., which force these semantic distinctions on the implementor; we therefore adapt the interface of DensityInterface.jl. Its main function logdensityof should suffice for variants, with the distinction being made by the capabilities of the concrete model instance.\n\nDensityInterface.jl also requires the trait function DensityKind, which is set to HasDensity() for the AbstractProbabilisticProgram type.  Additional functions\n\nDensityInterface.densityof(d, x) = exp(logdensityof(d, x))\nDensityInterface.logdensityof(d) = Base.Fix1(logdensityof, d)\nDensityInterface.densityof(d) = Base.Fix1(densityof, d)\n\nare provided automatically (repeated here for clarity).\n\nNote that logdensityof strictly generalizes logpdf, since the posterior density will of course in general be unnormalized and hence not a probability density.\n\nThe evaluation will usually work with the internal, concrete trace type, like VarInfo in Turing.jl:\n\nlogdensityof(m, vi)\n\nBut the user will more likely work on the interface using probability expressions:\n\nlogdensityof(m, @T(X = â€¦))\n\nDensities need (and usually, will) not be normalized.","category":"section"},{"location":"interface/#Implementation-notes","page":"Interface (outdated)","title":"Implementation notes","text":"It should be able to make this fall back on the internal method with the right definition and implementation of maketrace:\n\nlogdensityof(m, t::ProbabilityExpression) = logdensityof(m, maketrace(m, t))\n\nThere is one open question â€“ should normalized and unnormalized densities be able to be distinguished? This could be done by dispatch as well, e.g., if the caller wants to ensure normalization:\n\nlogdensityof(g, @T(X = â€¦, Y = â€¦, Z = â€¦); normalized=Val{true})\n\nAlthough there is proably a better way through traits; maybe like for arrays, with NormalizationStyle(g, t) = IsNormalized()?","category":"section"},{"location":"interface/#More-on-probability-expressions","page":"Interface (outdated)","title":"More on probability expressions","text":"Note that this needs to be a macro, if written this way, since the keys may themselves be more complex than just symbols (e.g., indexed variables.) (Don't hang yourselves up on that @T name though, this is just a working draft.)\n\nThe idea here is to standardize the construction (and manipulation) of abstract probability expressions, plus the interface for turning them into concrete traces for a specific model â€“ like @formula and apply_schema from StatsModels.jl are doing.\n\nMaybe the following would suffice to do that:\n\nmaketrace(m, t)::tracetype(m, t)\n\nwhere maketrace produces a concrete trace corresponding to t for the model m, and tracetype is the corresponding eltypeâ€“like function giving you the concrete trace type for a certain model and probability expression combination.\n\nPossible extensions of this idea:\n\nPerl-style do-notation: @T(Y = y | do(X = x))\nAllowing free variables, to specify model transformations: query(m, @T(X | Y))\n\"Graph queries\": @T(X | Parents(X)), @T(Y | Not(X)) (a nice way to express Gibbs conditionals!)\nPredicate style for \"measure queries\": @T(X < Y + Z)\n\nThe latter applications are the reason I originally liked the idea of the macro being called @P (or even @ð“… or @â„™), since then it would look like a \"Bayesian probability expression\": @P(X < Y + Z). But this would not be so meaningful in the case of representing a trace instance.\n\nPerhaps both @T and @P can coexist, and both produce different kinds of ProbabilityExpression objects?\n\nNB: the exact details of this kind of \"schema application\", and what results from it, will need to be specified in the interface of AbstractModelTrace, aka \"the new VarInfo\".","category":"section"},{"location":"interface/#AbstractModelTrace/VarInfo-interface-draft","page":"Interface (outdated)","title":"AbstractModelTrace/VarInfo interface draft","text":"","category":"section"},{"location":"interface/#Background","page":"Interface (outdated)","title":"Background","text":"","category":"section"},{"location":"interface/#Why-do-we-do-this?","page":"Interface (outdated)","title":"Why do we do this?","text":"As I have said before:\n\nThere are many aspects that make VarInfo a very complex data structure.\n\nCurrently, there is an insane amount of complexity and implementation details in DynamicPPL.jl's varinfo.jl, which has been rewritten multiple times with different concerns in mind â€“ most times to improve concrete needs of Turing.jl, such as type stability, or requirements of specific samplers.\n\nThis unfortunately makes VarInfo extremely opaque: it is hard to refactor without breaking anything (nobody really dares touching it), and a lot of knowledge about Turing.jl/DynamicPPL.jl internals is needed in order to judge the effects of changes.","category":"section"},{"location":"interface/#Design-choices","page":"Interface (outdated)","title":"Design choices","text":"Recently, @torfjelde has shown that a much simpler implementation is feasible â€“ basically, just a wrapped NamedTuple with a minimal interface.\n\nThe purpose of this proposal is twofold: first, to think about what a sufficient interface for AbstractModelTrace, the abstract supertype of VarInfo, should be, to allow multiple specialized variants and refactor the existing ones (typed/untyped and simple). Second, to view the problem as the design of an abstract data type: the specification of construction and modification mechanisms for a dictionary-like structure.\n\nRelated previous discussions:\n\nDiscussion about VarName\nAbstractVarInfo representation\n\nAdditionally (but closely related), the second part tries to formalize the \"subsumption\" mechanism of VarNames, and its interaction with using VarNames as keys/indices.\n\nOur discussions take place in what is a bit of a fuzzy zone between the part that is really \"abstract\", and meant for the wider purpuse of AbstractPPL.jl â€“ the implementation of probabilistic programming systems in general â€“ and our concrete needs within DPPL. I hope to always stay abstract and reusable; and there are already a couple of candidates for APPL clients other than DPPL, which will hopefully keep us focused: simulation based calibration, SimplePPL (a BUGS-like frontend), and ParetoSmoothing.jl.","category":"section"},{"location":"interface/#What-is-going-to-change?","page":"Interface (outdated)","title":"What is going to change?","text":"For the end user of Turing.jl: nothing. You usually don't use VarInfo, or the raw evaluator interface, anyways. (Although if the newer data structures are more user-friendly, they might occur in more places in the future?)\nFor people having a look into code using VarInfo, or starting to hack on Turing.jl/DPPL.jl: a huge reduction in cognitive complexity. VarInfo implementations should be readable on their own, and the implemented functions layed out somewhere. Its usages should look like for any other nice, normal data structure.\nFor core DPPL.jl implementors: same as the previous, plus: a standard against which to improve and test VarInfo, and a clearly defined design space for new data structures.\nFor AbstractPPL.jl clients/PPL implementors: an interface to program against (as with the rest of APPL), and an existing set of well-specified, flexible trace data types with different characteristics.\n\nAnd in terms of implementation work in DPPL.jl: once the interface is fixed (or even during fixing it), varinfo.jl will undergo a heavy refactoring â€“ which should make it simpler! (No three different getter functions with slightly different semantics, etcâ€¦).","category":"section"},{"location":"interface/#Property-interface","page":"Interface (outdated)","title":"Property interface","text":"The basic idea is for all VarInfos to behave like ordered dictionaries with VarName keys â€“ all common operations should just work. There are two things that make them more special, though:\n\n\"Fancy indexing\": since VarNames are structured themselves, the VarInfo should be have a bit like a trie, in the sense that all prefixes of stored keys should be retrievable.  Also, subsumption of VarNames should be respected (see end of this document):\nvi[@varname(x.a)] = [1, 2, 3]\nvi[@varname(x.b)] = [4, 5, 6]\nvi[@varname(x.a[2])] == 2\nvi[@varname(x)] == (; a=[1, 2, 3], b=[4, 5, 6])\nGeneralizations that go beyond simple cases (those that you can imagine by storing individual setfield!s in a tree) need not be implemented in the beginning; e.g.,\nvi[@varname(x[1])] = 1\nvi[@varname(x[2])] = 2\nkeys(vi) == [x[1], x[2]]\n\nvi[@varname(x)] = [1, 2]\nkeys(vi) == [x]\n(This has to be discussed further.)  Information other than the sampled values, such as flags, metadata, pointwise likelihoods, etc., can in principle be stored in multiple of these \"VarInfo dicts\" with parallel structure.  For efficiency, it is thinkable to devise a design such that multiple fields can be stored under the same indexing structure.\nvi[@varname(x[1])] == 1\nvi[@varname(x[1])].meta[\"bla\"] == false\nor something in that direction.\n(This is logically equivalent to a dictionary with named tuple values.  Maybe we can do what DictTable does?)\nThe old order field, indicating at which position in the evaluator function a variable has been added (essentially a counter of insertions) can actually be left out completely, since the dictionary is specified to be ordered by insertion.\nThe important question here is: should the \"joint data structure\" behave like a dictionary of NamedTuples (eltype(vi) == @NamedTuple{value::T, â„“::Float64, meta}), or like a struct of dicts with shared keys (eltype(vi.value) <: T, eltype(vi.â„“) <: Float64, â€¦)?\n\nThe required dictionary functions are about the following:\n\nPure functions:\niterate, yielding pairs of VarName and the stored value\nIteratorEltype == HasEltype(), IteratorSize = HasLength()\nkeys, values, pairs, length consistent with iterate\neltype, keytype, valuetype\nget, getindex, haskey for indexing by VarName\nmerge to join two VarInfos\nMutating functions:\ninsert!!, set!!\nmerge!! to add and join elements (TODO: think about merge)\nsetindex!!\nempty!!, delete!!, unset!! (Are these really used anywhere? Not having them makes persistent implementations much easier!)\n\nI believe that adopting the interface of Dictionaries.jl, not Base.AbstractDict, would be ideal, since their approach make key sharing and certain operations naturally easy (particularly \"broadcast-style\", i.e., transformations on the values, but not the keys).\n\nOther Base functions, like enumerate, should follow from the above.\n\nlength might appear weird â€“ but it should definitely be consistent with the iterator.\n\nIt would be really cool if merge supported the combination of distinct types of implementations, e.g., a dynamic and a tuple-based part.\n\nTo support both mutable and immutable/persistent implementations, let's require consistent BangBang.jl style mutators throughout.","category":"section"},{"location":"interface/#Transformations/Bijectors","page":"Interface (outdated)","title":"Transformations/Bijectors","text":"Transformations should ideally be handled explicitly and from outside: automatically by the compiler macro, or at the places required by samplers.\n\nImplementation-wise, they can probably be expressed as folds?\n\nmap(v -> link(v.dist, v.value), vi)","category":"section"},{"location":"interface/#Linearization","page":"Interface (outdated)","title":"Linearization","text":"There are multiple possible approaches to handle this:\n\nAs a special case of conversion: Vector(vi)\ncopy!(vals_array, vi).\nAs a fold: mapreduce(v -> vec(v.value), append!, vi, init=Float64[])\n\nAlso here, I think that the best implementation would be through a fold. Variants (1) or (2) might additionally be provided as syntactic sugar.","category":"section"},{"location":"interface/#VarName-based-axioms","page":"Interface (outdated)","title":"VarName-based axioms","text":"What follows is mostly an attempt to formalize subsumption.\n\nFirst, remember that in Turing.jl we can always work with concretized VarNames: begin/end, :, and boolean indexing are all turned into some form of concrete cartesian or array indexing (assuming this suggestion being implemented). This makes all index comparisons static.\n\nNow, VarNames have a compositional structure: they can be built by composing a root variable with more and more lenses (VarName{v}() starts off with an IdentityLens):\n\njulia> Accessors.IndexLens((2,)) âˆ˜ Accessors.IndexLens((1:10, 1)) âˆ˜ VarName{:x}()\nx[1:10, 1][2]\n\nBy \"subsumption\", we mean the notion of a VarName expressing a more nested path than another one:\n\nsubsumes(@varname(x.a), @varname(x.a[1]))\n@varname(x.a) âŠ’ @varname(x.a[1]) # \\sqsupseteq\n@varname(x.a) â‹¢ @varname(x.a[1]) # \\nsqsubseteq\n\nThus, we have the following axioms for VarNames (\"variables\" are VarName{n}()):\n\nx âŠ‘ x for all variables x\nx â‰ y for x â‰  y (i.e., distinct variables are incomparable; x â‹¢ y and y â‹¢ x) (â‰ is \\asymp)\nx âˆ˜ â„“ âŠ‘ x for all variables x and lenses â„“\nx âˆ˜ â„“â‚ âŠ‘ x âˆ˜ â„“â‚‚ â‡” â„“â‚ âŠ‘ â„“â‚‚\n\nFor the last axiom to work, we also have to define subsumption of individual, non-composed lenses:\n\nPropertyLens(a) == PropertyLens(b) â‡” a == b, for all symbols a, b\nFunctionLens(f) == FunctionLens(g) â‡” f == g (under extensional equality; I'm only mentioning this in case we ever generalize to Bijector-ed variables like @varname(log(x)))\nIndexLens(Î¹â‚) âŠ‘ IndexLens(Î¹â‚‚) if the index tuple Î¹â‚‚ covers all indices in Î¹â‚; for example, _[1, 2:10] âŠ‘ _[1:10, 1:20].  (This is a bit fuzzy and not all corner cases have been considered yet!)\nIdentityLens() == IdentityLens()\nâ„“â‚ â‰ â„“â‚‚, otherwise\n\nTogether, this should make VarNames under subsumption a reflexive poset.\n\nThe fundamental requirement for VarInfos is then:\n\nvi[x âˆ˜ â„“] == get(vi[x], â„“)\n\nSo we always want the following to work, automatically:\n\nvi = insert!!(vi, vn, x)\nvi[vn] == x\n\n(the trivial case), and\n\nx = set!!(x, â„“â‚, a)\nx = set!!(x, â„“â‚‚, b)\nvi = insert!!(vi, vn, x)\nvi[vn âˆ˜ â„“â‚] == a\nvi[vn âˆ˜ â„“â‚‚] == b\n\nsince vn subsumes both vn âˆ˜ â„“â‚ and vn âˆ˜ â„“â‚‚.\n\nWhether the opposite case is supported may depend on the implementation. The most complicated part is \"unification\":\n\nvi = insert!!(vi, vn âˆ˜ â„“â‚, a)\nvi = insert!!(vi, vn âˆ˜ â„“â‚‚, b)\nget(vi[vn], â„“â‚) == a\nget(vi[vn], â„“â‚‚) == b\n\nwhere vn âˆ˜ â„“â‚ and vn âˆ˜ â„“â‚‚ need to be recognized as \"children\" of a common parent vn.","category":"section"},{"location":"varname/#VarNames-and-optics","page":"VarNames and optics","title":"VarNames and optics","text":"","category":"section"},{"location":"varname/#VarNames:-an-overview","page":"VarNames and optics","title":"VarNames: an overview","text":"One of the most important parts of AbstractPPL.jl is the VarName type, which is used throughout the TuringLang ecosystem to represent names of random variables.\n\nFundamentally, a VarName comprises a symbol (which represents the name of the variable itself) and an optic (which tells us which part of the variable we might be interested in). For example, x.a[1] means the first element of the field a of the variable x. Here, x is the symbol, and .a[1] is the optic.\n\nVarNames can be created using the @varname macro:\n\nusing AbstractPPL\n\nvn = @varname(x.a[1])\n\nYou can obtain the components of a VarName using the getsym and getoptic functions:\n\ngetsym(vn), getoptic(vn)","category":"section"},{"location":"varname/#Dynamic-indices","page":"VarNames and optics","title":"Dynamic indices","text":"VarNames may contain 'dynamic' indices, that is, indices whose meaning is not known until they are resolved against a specific value. For example, x[end] refers to the last element of x; but we don't know what that means until we know what x is.\n\nSpecifically, begin and end symbols in indices are treated as dynamic indices. This is also true for any expression that contains begin or end, such as end-1 or 1:3:end.\n\nDynamic indices are represented using an internal type, AbstractPPL.DynamicIndex.\n\nvn_dyn = @varname(x[1:2:end])\n\nYou can detect whether a VarName contains dynamic indices using the is_dynamic function:\n\nis_dynamic(vn_dyn)\n\nThese dynamic indices can be resolved, or concretized, by passing a specific value to the concretize function:\n\nx = randn(5)\nvn_conc = concretize(vn_dyn, x)","category":"section"},{"location":"varname/#Optics","page":"VarNames and optics","title":"Optics","text":"The optics used in AbstractPPL.jl are represented as a linked list. For example, the optic .a[1] is a Property optic that contains an Index optic as its child. That means that the 'elements' of the linked list can be read from left-to-right:\n\nProperty{:a} -> Index{1} -> Iden\n\nAll optic linked lists are terminated with an Iden optic, which represents the identity function.\n\noptic = getoptic(@varname x.a[1])\ndump(optic)\n\nInstead of calling getoptic(@varname(...)), you can directly use the @opticof macro to create optics:\n\noptic = @opticof(_.a[1])","category":"section"},{"location":"varname/#Getting-and-setting","page":"VarNames and optics","title":"Getting and setting","text":"Optics are callable structs, and when passed a value will extract the relevant part of that value.\n\ndata = (a=[10, 20, 30], b=\"hello\")\noptic = @opticof(_.a[2])\noptic(data)\n\nYou can set values using Accessors.set (which AbstractPPL re-exports). Note, though, that this will not mutate the original value. Furthermore, you cannot use the handy macros like Accessors.@set, since those will use the optics from Accessors.jl.\n\nnew_data = set(data, optic, 99)\nnew_data, data\n\nIf you want to try to mutate values, you can wrap an optic using with_mutation.\n\noptic_mut = with_mutation(optic)\nset(data, optic_mut, 99)\ndata","category":"section"},{"location":"varname/#Composing-and-decomposing-optics","page":"VarNames and optics","title":"Composing and decomposing optics","text":"If you have two optics, you can compose them using the âˆ˜ operator:\n\noptic1 = @opticof(_.a)\noptic2 = @opticof(_[1])\ncomposed = optic2 âˆ˜ optic1\n\nNotice the order of composition here, which can be counterintuitive: optic2 âˆ˜ optic1 means \"first apply optic1, then apply optic2\", and thus this represents the optic .a[1] (not .[1].a).\n\nBase.cat(optics...) is also provided, which composes optics in a more intuitive sense (indeed, if you think of an optic as a linked list, this can be thought of as concatenating the lists). The following is equivalent to the previous example:\n\ncomposed2 = Base.cat(optic1, optic2)\n\nappend_optic is a shortcut for 'composing' an optic with a VarName.\n\nSeveral functions are provided to decompose optics, which all stem from their linked-list structure. Their names directly mirror Haskell's functions for decomposing lists, but are prefixed with o:\n\nFor example, ohead returns the first element of the optic linked list, and otail returns the rest of the list after removing the head:\n\noptic = @opticof(_.a[1].b[2])\nohead(optic), otail(optic)\n\nConvesely, oinit returns the optic linked list without its last element, and olast returns the last element:\n\noinit(optic), olast(optic)\n\nIf the optic only has a single element, then oinit and otail return Iden, while ohead and olast return the optic itself:\n\noptic_single = @opticof(_.a)\noinit(optic_single), olast(optic_single), ohead(optic_single), otail(optic_single)","category":"section"},{"location":"varname/#Converting-VarNames-to-optics-and-back","page":"VarNames and optics","title":"Converting VarNames to optics and back","text":"Sometimes it is useful to treat a VarName's top level symbol as if it were part of the optic. For example, when indexing into a NamedTuple nt, we might want to treat the entire VarName x.a[1] as an optic that can be applied to a NamedTuple: i.e., we want to access the nt.x field rather than the variable x itself. This can be achieved with:","category":"section"},{"location":"varname/#Subsumption","page":"VarNames and optics","title":"Subsumption","text":"Sometimes, we want to check whether one VarName 'subsumes' another; that is, whether a VarName refers to a part of another VarName. This is done using the subsumes function:\n\nvn1 = @varname(x.a)\nvn2 = @varname(x.a[1])\nsubsumes(vn1, vn2)","category":"section"},{"location":"varname/#Prefixing-and-unprefixing","page":"VarNames and optics","title":"Prefixing and unprefixing","text":"Composing two optics can be done using the âˆ˜ operator, as shown above. But what if we want to compose two VarNames? This is used, for example, in DynamicPPL's submodel functionality.","category":"section"},{"location":"varname/#VarName-leaves","page":"VarNames and optics","title":"VarName leaves","text":"The following functions are used to extract the 'leaves' of a VarName, that is, the atomic components of a VarName that do not have any further substructure. For example, for a vector variable x, the leaves would be x[1], x[2], etc.","category":"section"},{"location":"varname/#Reading-from-a-container-with-a-VarName-(or-optic)","page":"VarNames and optics","title":"Reading from a container with a VarName (or optic)","text":"","category":"section"},{"location":"varname/#Serializing-VarNames","page":"VarNames and optics","title":"Serializing VarNames","text":"","category":"section"},{"location":"varname/#AbstractPPL.VarName","page":"VarNames and optics","title":"AbstractPPL.VarName","text":"VarName{sym}(optic=identity)\n\nA variable identifier for a symbol sym and optic optic. sym refers to the name of the  top-level Julia variable, while optic allows one to specify a particular property or index inside that variable.\n\nVarNames can be manually constructed using the VarName{sym}(optic) constructor, or from an optic expression through the @varname convenience macro.\n\n\n\n\n\n","category":"type"},{"location":"varname/#AbstractPPL.@varname","page":"VarNames and optics","title":"AbstractPPL.@varname","text":"@varname(expr, concretize=false)\n\nCreate a VarName given an expression expr representing a variable or part of it.\n\nBasic examples\n\nIn general, VarNames must have a top-level symbol representing the identifier itself, and can then have any number of property accesses or indexing operations chained to it.\n\njulia> @varname(x)\nx\n\njulia> @varname(x.a.b.c)\nx.a.b.c\n\njulia> @varname(x[1][2][3])\nx[1][2][3]\n\njulia> @varname(x.a[1:3].b[2])\nx.a[1:3].b[2]\n\nDynamic indices\n\nSome expressions may involve dynamic indices, specifically, begin, end. These indices cannot be resolved, or 'concretized', until the value being indexed into is known. By default, @varname(...) will not automatically concretize these expressions, and thus the resulting VarName will contain markers for these.\n\nNote that colons are not considered dynamic.\n\njulia> vn = @varname(x[end])\nx[DynamicIndex(end)]\n\njulia> vn = @varname(x[1, end-1])\nx[1, DynamicIndex(end - 1)]\n\nYou can detect whether a VarName contains any dynamic indices using is_dynamic:\n\njulia> vn = @varname(x[1, end-1]); AbstractPPL.is_dynamic(vn)\ntrue\n\nTo concretize such expressions, you can call concretize on the resulting VarName. After concretization, the resulting VarName will no longer be dynamic.\n\njulia> x = randn(2, 3);\n\njulia> vn = @varname(x[1, end-1]); vn2 = AbstractPPL.concretize(vn, x)\nx[1, 2]\n\njulia> getoptic(vn2).ix  # Just an ordinary tuple.\n(1, 2)\n\njulia> AbstractPPL.is_dynamic(vn2)\nfalse\n\nAlternatively, you can pass true as the second positional argument to the @varname macro (note that it is not a keyword argument!). This will automatically call concretize for you, using the top-level symbol to look up the value used for concretization.\n\njulia> x = randn(2, 3);\n\njulia> @varname(x[1:end, end][:], true)\nx[1:2, 3][:]\n\nInterpolation\n\nProperty names, as well as top-level symbols, can also be constructed from interpolated symbols:\n\njulia> name = :hello; @varname(x.$name)\nx.hello\n\njulia> @varname($name)\nhello\n\njulia> @varname($name.a.$name[1])\nhello.a.hello[1]\n\nFor indices, you do not need to use $ to interpolate, just use the variable directly:\n\njulia> ix = 2; @varname(x[ix])\nx[2]\n\nNote that if the top-level symbol is interpolated, automatic concretization is not possible:\n\njulia> name = :x; @varname($name[1:end], true)\nERROR: LoadError: cannot automatically concretize VarName with interpolated top-level symbol; call `concretize(vn, val)` manually instead\n[...]\n\n\n\n\n\n","category":"macro"},{"location":"varname/#AbstractPPL.varname","page":"VarNames and optics","title":"AbstractPPL.varname","text":"varname(expr, concretize::Bool)\n\nImplementation of the @varname macro. See the documentation for @varname for details. This function is exported to allow other macros (e.g. in DynamicPPL) to reuse the same logic.\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.getsym","page":"VarNames and optics","title":"AbstractPPL.getsym","text":"getsym(vn::VarName)\n\nReturn the symbol of the Julia variable used to generate vn.\n\nExamples\n\njulia> getsym(@varname(x[1][2:3]))\n:x\n\njulia> getsym(@varname(y))\n:y\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.getoptic","page":"VarNames and optics","title":"AbstractPPL.getoptic","text":"getoptic(vn::VarName)\n\nReturn the optic of the Julia variable used to generate vn.\n\nExamples\n\njulia> getoptic(@varname(x[1][2:3]))\nOptic([1][2:3])\n\njulia> getoptic(@varname(y))\nOptic()\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.is_dynamic","page":"VarNames and optics","title":"AbstractPPL.is_dynamic","text":"is_dynamic(vn::VarName)\n\nReturn true if vn contains any dynamic indices (i.e., begin and end). If a VarName has been concretized, this will always return false.\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.concretize","page":"VarNames and optics","title":"AbstractPPL.concretize","text":"concretize(idx::Index, val)\n\nRecursively concretize all dynamic indices in idx (including its child optics) against val.\n\n\n\n\n\nconcretize(vn::VarName, x)\n\nReturn vn concretized on x, i.e. any information related to the runtime shape of x is evaluated. This will convert any begin and end indices in vn to concrete indices with information about the length of the dimension being indexed into.\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.AbstractOptic","page":"VarNames and optics","title":"AbstractPPL.AbstractOptic","text":"AbstractOptic\n\nAn abstract type that represents the non-symbol part of a VarName, i.e., the section of the variable that is of interest. For example, in x.a[1][2], the AbstractOptic represents the .a[1][2] part.\n\n\n\n\n\n","category":"type"},{"location":"varname/#AbstractPPL.Property","page":"VarNames and optics","title":"AbstractPPL.Property","text":"Property{sym}(child=Iden())\n\nA property access optic representing access to property sym. A VarName{:x} with this optic represents access to x.sym. The child optic represents any further indexing or property access after this property access operation.\n\n\n\n\n\n","category":"type"},{"location":"varname/#AbstractPPL.Index","page":"VarNames and optics","title":"AbstractPPL.Index","text":"Index(ix, kw, child=Iden())\n\nAn indexing optic representing access to indices ix, which may also take the form of keyword arguments kw. A VarName{:x} with this optic represents access to x[ix..., kw...]. The child optic represents any further indexing or property access after this indexing operation.\n\n\n\n\n\n","category":"type"},{"location":"varname/#AbstractPPL.Iden","page":"VarNames and optics","title":"AbstractPPL.Iden","text":"Iden()\n\nThe identity optic. This is the optic used when we are referring to the entire variable. It is also the base case for composing optics.\n\n\n\n\n\n","category":"type"},{"location":"varname/#AbstractPPL.@opticof","page":"VarNames and optics","title":"AbstractPPL.@opticof","text":"@opticof(expr, concretize=false)\n\nExtract the optic from @varname(expr, concretize). This is a thin wrapper around getoptic(@varname(...)).\n\nIf you don't need to concretize, you should use _ as the top-level symbol to indicate that it is not relevant:\n\njulia> @opticof(_.a.b)\nOptic(.a.b)\n\nIf you need to concretize, then you can provide a real variable name (which is then used to look up the value for concretization):\n\njulia> x = randn(3, 4); @opticof(x[1:end, end], true)\nOptic([1:3, 4])\n\nNote that concretization with @opticof has the same limitations as with @varname, specifically, if the top-level symbol is interpolated, automatic concretization is not possible.\n\n\n\n\n\n","category":"macro"},{"location":"varname/#AbstractPPL.with_mutation","page":"VarNames and optics","title":"AbstractPPL.with_mutation","text":"with_mutation(o::AbstractOptic)\n\nCreate a version of the optic o which attempts to mutate its input where possible.\n\nOn their own, AbstractOptics are non-mutating:\n\njulia> optic = @opticof(_[1])\nOptic([1])\n\njulia> x = [0.0, 0.0];\n\njulia> set(x, optic, 1.0); x\n2-element Vector{Float64}:\n 0.0\n 0.0\n\nWith this function, we can create a mutating version of the optic:\n\njulia> optic_mut = with_mutation(@opticof(_[1]))\nOptic!!([1])\n\njulia> x = [0.0, 0.0];\n\njulia> set(x, optic_mut, 1.0); x\n2-element Vector{Float64}:\n 1.0\n 0.0\n\nThanks to the BangBang.jl package, this optic will gracefully fall back to non-mutating behaviour if mutation is not possible. For example, if we try to use it on a tuple:\n\njulia> optic_mut = with_mutation(@opticof(_[1]))\nOptic!!([1])\n\njulia> x = (0.0, 0.0);\n\njulia> set(x, optic_mut, 1.0); x\n(0.0, 0.0)\n\n\n\n\n\n","category":"function"},{"location":"varname/#Base.:âˆ˜-Tuple{AbstractOptic, AbstractOptic}","page":"VarNames and optics","title":"Base.:âˆ˜","text":"âˆ˜(outer::AbstractOptic, inner::AbstractOptic)\n\nCompose two AbstractOptics together.\n\njulia> p1 = @opticof(_.a[1])\nOptic(.a[1])\n\njulia> p2 = @opticof(_.b[2, 3])\nOptic(.b[2, 3])\n\njulia> p1 âˆ˜ p2\nOptic(.b[2, 3].a[1])\n\n\n\n\n\n","category":"method"},{"location":"varname/#Base.cat-Tuple{Vararg{AbstractOptic}}","page":"VarNames and optics","title":"Base.cat","text":"cat(optics::AbstractOptic...)\n\nCompose multiple AbstractOptics together. The optics should be provided from innermost to outermost, i.e., cat(o1, o2, o3) corresponds to o3 âˆ˜ o2 âˆ˜ o1.\n\n\n\n\n\n","category":"method"},{"location":"varname/#AbstractPPL.append_optic","page":"VarNames and optics","title":"AbstractPPL.append_optic","text":"append_optic(vn::VarName, optic::AbstractOptic)\n\nCompose optic with the optic in vn, returning a new VarName.\n\noptic is placed at the tail of the existing optic, e.g.\n\njulia> vn = @varname(x.a.b)\nx.a.b\n\njulia> append_optic(vn, @opticof(_[1]))\nx.a.b[1]\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.ohead","page":"VarNames and optics","title":"AbstractPPL.ohead","text":"ohead(optic::AbstractOptic)\n\nGet the innermost layer of an optic. For all optics, we have that otail(optic) âˆ˜ ohead(optic) == optic.\n\njulia> ohead(@opticof _.a[1][2])\nOptic(.a)\n\njulia> ohead(@opticof _)\nOptic()\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.otail","page":"VarNames and optics","title":"AbstractPPL.otail","text":"otail(optic::AbstractOptic)\n\nGet everything but the innermost layer of an optic. For all optics, we have that otail(optic) âˆ˜ ohead(optic) == optic.\n\njulia> otail(@opticof _.a[1][2])\nOptic([1][2])\n\njulia> otail(@opticof _)\nOptic()\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.oinit","page":"VarNames and optics","title":"AbstractPPL.oinit","text":"oinit(optic::AbstractOptic)\n\nGet everything but the outermost layer of an optic. For all optics, we have that olast(optic) âˆ˜ oinit(optic) == optic.\n\njulia> oinit(@opticof _.a[1][2])\nOptic(.a[1])\n\njulia> oinit(@opticof _)\nOptic()\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.olast","page":"VarNames and optics","title":"AbstractPPL.olast","text":"olast(optic::AbstractOptic)\n\nGet the outermost layer of an optic. For all optics, we have that olast(optic) âˆ˜ oinit(optic) == optic.\n\njulia> olast(@opticof _.a[1][2])\nOptic([2])\n\njulia> olast(@opticof _)\nOptic()\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.varname_to_optic","page":"VarNames and optics","title":"AbstractPPL.varname_to_optic","text":"varname_to_optic(vn::VarName)\n\nConvert a VarName to an optic, by converting the top-level symbol to a Property optic.\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.optic_to_varname","page":"VarNames and optics","title":"AbstractPPL.optic_to_varname","text":"optic_to_varname(optic::Property{sym}) where {sym}\n\nConvert a Property optic to a VarName, by converting the top-level property to a symbol. This fails for all other optics.\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.subsumes","page":"VarNames and optics","title":"AbstractPPL.subsumes","text":"subsumes(parent::VarName, child::VarName)\n\nCheck whether the variable name child describes a sub-range of the variable parent, i.e., is contained within it.\n\njulia> subsumes(@varname(x), @varname(x[1, 2]))\ntrue\n\njulia> subsumes(@varname(x[1, 2]), @varname(x[1, 2][3]))\ntrue\n\nThis is done by recursively comparing each layer of the VarNames' optics.\n\nNote that often this is not possible to determine statically, and so the results should not be over-interpreted. In particular, Index optics  pose a problem. An i::Index will only subsume j::Index if:\n\nThey have the same number of positional indices (i.ix and j.ix);\nEach positional index in i can be determined to comprise the corresponding positional index in j; and\nThe keyword indices of i (i.kw) are a superset of those in j.kw).\n\nIn all other cases, subsumes will conservatively return false, even though in practice it might well be that i does subsume j. Some examples where subsumption cannot be determined statically are:\n\nSubsumption between different forms of indexing is not supported, e.g. x[4] and x[2, 2] are not considered to subsume each other, even though they might in practice (e.g. if x is a 2x2 matrix).\nWhen dynamic indices (that are not equal) are present. (Dynamic indices that are equal do subsume each other.)\nNon-standard indices, e.g. Not(4), 2..3, etc. Again, these only subsume each other when they are equal.\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.prefix","page":"VarNames and optics","title":"AbstractPPL.prefix","text":"prefix(vn::VarName, prefix::VarName)\n\nAdd a prefix to a VarName.\n\njulia> prefix(@varname(x), @varname(y))\ny.x\n\njulia> prefix(@varname(x.a), @varname(y))\ny.x.a\n\njulia> prefix(@varname(x.a), @varname(y[1]))\ny[1].x.a\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.unprefix","page":"VarNames and optics","title":"AbstractPPL.unprefix","text":"unprefix(vn::VarName, prefix::VarName)\n\nRemove a prefix from a VarName.\n\njulia> unprefix(@varname(y.x), @varname(y))\nx\n\njulia> unprefix(@varname(y.x.a), @varname(y))\nx.a\n\njulia> unprefix(@varname(y[1].x), @varname(y[1]))\nx\n\njulia> unprefix(@varname(y), @varname(n))\nERROR: ArgumentError: cannot remove prefix n from VarName y\n[...]\n\njulia> unprefix(@varname(y[1]), @varname(y))\nERROR: ArgumentError: optic_to_varname: can only convert Property optics to VarName\n[...]\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.varname_leaves","page":"VarNames and optics","title":"AbstractPPL.varname_leaves","text":"varname_leaves(vn::VarName, val)\n\nReturn an iterator over all varnames that are represented by vn on val.\n\nExamples\n\njulia> using AbstractPPL: varname_leaves\n\njulia> foreach(println, varname_leaves(@varname(x), rand(2)))\nx[1]\nx[2]\n\njulia> foreach(println, varname_leaves(@varname(x[1:2]), rand(2)))\nx[1:2][1]\nx[1:2][2]\n\njulia> x = (y = 1, z = [[2.0], [3.0]]);\n\njulia> foreach(println, varname_leaves(@varname(x), x))\nx.y\nx.z[1][1]\nx.z[2][1]\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.varname_and_value_leaves","page":"VarNames and optics","title":"AbstractPPL.varname_and_value_leaves","text":"varname_and_value_leaves(vn::VarName, val)\n\nReturn an iterator over all varname-value pairs that are represented by vn on val.\n\nExamples\n\njulia> using AbstractPPL: varname_and_value_leaves\n\njulia> foreach(println, varname_and_value_leaves(@varname(x), 1:2))\n(x[1], 1)\n(x[2], 2)\n\njulia> foreach(println, varname_and_value_leaves(@varname(x[1:2]), 1:2))\n(x[1:2][1], 1)\n(x[1:2][2], 2)\n\njulia> x = (y = 1, z = [[2.0], [3.0]]);\n\njulia> foreach(println, varname_and_value_leaves(@varname(x), x))\n(x.y, 1)\n(x.z[1][1], 2.0)\n(x.z[2][1], 3.0)\n\nThere is also some special handling for certain types:\n\njulia> using LinearAlgebra\n\njulia> x = reshape(1:4, 2, 2);\n\njulia> # `LowerTriangular`\n       foreach(println, varname_and_value_leaves(@varname(x), LowerTriangular(x)))\n(x[1, 1], 1)\n(x[2, 1], 2)\n(x[2, 2], 4)\n\njulia> # `UpperTriangular`\n       foreach(println, varname_and_value_leaves(@varname(x), UpperTriangular(x)))\n(x[1, 1], 1)\n(x[1, 2], 3)\n(x[2, 2], 4)\n\njulia> # `Cholesky` with lower-triangular\n       foreach(println, varname_and_value_leaves(@varname(x), Cholesky([1.0 0.0; 0.0 1.0], 'L', 0)))\n(x.L[1, 1], 1.0)\n(x.L[2, 1], 0.0)\n(x.L[2, 2], 1.0)\n\njulia> # `Cholesky` with upper-triangular\n       foreach(println, varname_and_value_leaves(@varname(x), Cholesky([1.0 0.0; 0.0 1.0], 'U', 0)))\n(x.U[1, 1], 1.0)\n(x.U[1, 2], 0.0)\n(x.U[2, 2], 1.0)\n\n\n\n\n\nvarname_and_value_leaves(container)\n\nReturn an iterator over all varname-value pairs that are represented by container.\n\nThis is the same as varname_and_value_leaves(vn::VarName, x) but over a container containing multiple varnames.\n\nSee also: varname_and_value_leaves(vn::VarName, x).\n\nExamples\n\njulia> using AbstractPPL: varname_and_value_leaves\n\njulia> using OrderedCollections: OrderedDict\n\njulia> # With an `AbstractDict` (we use `OrderedDict` here\n       # to ensure consistent ordering in doctests)\n       dict = OrderedDict(@varname(y) => 1, @varname(z) => [[2.0], [3.0]]);\n\njulia> foreach(println, varname_and_value_leaves(dict))\n(y, 1)\n(z[1][1], 2.0)\n(z[2][1], 3.0)\n\njulia> # With a `NamedTuple`\n       nt = (y = 1, z = [[2.0], [3.0]]);\n\njulia> foreach(println, varname_and_value_leaves(nt))\n(y, 1)\n(z[1][1], 2.0)\n(z[2][1], 3.0)\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.canview","page":"VarNames and optics","title":"AbstractPPL.canview","text":"canview(optic, container)\n\nReturn true if optic can be used to view container, and false otherwise.\n\nExamples\n\njulia> AbstractPPL.canview(@opticof(_.a), (a = 1.0, ))\ntrue\n\njulia> AbstractPPL.canview(@opticof(_.a), (b = 1.0, )) # property `a` does not exist\nfalse\n\njulia> AbstractPPL.canview(@opticof(_.a[1]), (a = [1.0, 2.0], ))\ntrue\n\njulia> AbstractPPL.canview(@opticof(_.a[3]), (a = [1.0, 2.0], )) # out of bounds\nfalse\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.hasvalue","page":"VarNames and optics","title":"AbstractPPL.hasvalue","text":"hasvalue(\n    vals::Union{AbstractDict,NamedTuple},\n    vn::VarName,\n    dist::Distribution;\n    error_on_incomplete::Bool=false\n)\n\nCheck if vals contains values for vn that is compatible with the distribution dist.\n\nThis is a more general version of hasvalue(vals, vn), in that even if vn itself is not inside vals, it further checks if vals contains sub-values of vn that can be used to reconstruct vn given dist.\n\nThe error_on_incomplete flag can be used to detect cases where some of the values needed for vn are present, but others are not. This may help to detect invalid cases where the user has provided e.g. data of the wrong shape.\n\nNote that this check is only possible if a Dict is passed, because the key type of a NamedTuple (i.e., Symbol) is not rich enough to carry indexing information. If this method is called with a NamedTuple, it will just defer to hasvalue(vals, vn).\n\nFor example:\n\njulia> d = Dict(@varname(x[1]) => 1.0, @varname(x[2]) => 2.0);\n\njulia> hasvalue(d, @varname(x), MvNormal(zeros(2), I))\ntrue\n\njulia> hasvalue(d, @varname(x), MvNormal(zeros(3), I))\nfalse\n\njulia> hasvalue(d, @varname(x), MvNormal(zeros(3), I); error_on_incomplete=true)\nERROR: only partial values for `x` found in the dictionary provided\n[...]\n\n\n\n\n\nhasvalue(vals::NamedTuple, vn::VarName)\nhasvalue(vals::AbstractDict{<:VarName}, vn::VarName)\n\nDetermine whether vals contains a value for a given vn.\n\nExamples\n\nWith x as a NamedTuple:\n\njulia> hasvalue((x = 1.0, ), @varname(x))\ntrue\n\njulia> hasvalue((x = 1.0, ), @varname(x[1]))\nfalse\n\njulia> hasvalue((x = [1.0],), @varname(x))\ntrue\n\njulia> hasvalue((x = [1.0],), @varname(x[1]))\ntrue\n\njulia> hasvalue((x = [1.0],), @varname(x[2]))\nfalse\n\nWith x as a AbstractDict:\n\njulia> hasvalue(Dict(@varname(x) => 1.0, ), @varname(x))\ntrue\n\njulia> hasvalue(Dict(@varname(x) => 1.0, ), @varname(x[1]))\nfalse\n\njulia> hasvalue(Dict(@varname(x) => [1.0]), @varname(x))\ntrue\n\njulia> hasvalue(Dict(@varname(x) => [1.0]), @varname(x[1]))\ntrue\n\njulia> hasvalue(Dict(@varname(x) => [1.0]), @varname(x[2]))\nfalse\n\nIn the AbstractDict case we can also have keys such as v[1]:\n\njulia> vals = Dict(@varname(x[1]) => [1.0,]);\n\njulia> hasvalue(vals, @varname(x[1])) # same as `haskey`\ntrue\n\njulia> hasvalue(vals, @varname(x[1][1])) # different from `haskey`\ntrue\n\njulia> hasvalue(vals, @varname(x[1][2]))\nfalse\n\njulia> hasvalue(vals, @varname(x[2][1]))\nfalse\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.getvalue","page":"VarNames and optics","title":"AbstractPPL.getvalue","text":"getvalue(\n    vals::Union{AbstractDict,NamedTuple},\n    vn::VarName,\n    dist::Distribution\n)\n\nRetrieve the value of vn from vals, using the distribution dist to reconstruct the value if necessary.\n\nThis is a more general version of getvalue(vals, vn), in that even if vn itself is not inside vals, it can still reconstruct the value of vn from sub-values of vn that are present in vals.\n\nNote that this reconstruction is only possible if a Dict is passed, because the key type of a NamedTuple (i.e., Symbol) is not rich enough to carry indexing information. If this method is called with a NamedTuple, it will just defer to getvalue(vals, vn).\n\nFor example:\n\njulia> d = Dict(@varname(x[1]) => 1.0, @varname(x[2]) => 2.0);\n\njulia> getvalue(d, @varname(x), MvNormal(zeros(2), I))\n2-element Vector{Float64}:\n 1.0\n 2.0\n\njulia> # Use `hasvalue` to check for this case before calling `getvalue`.\n       getvalue(d, @varname(x), MvNormal(zeros(3), I))\nERROR: `x` was not found in the dictionary provided\n[...]\n\n\n\n\n\ngetvalue(vals::NamedTuple, vn::VarName)\ngetvalue(vals::AbstractDict{<:VarName}, vn::VarName)\n\nReturn the value(s) in vals represented by vn.\n\nExamples\n\nFor NamedTuple:\n\njulia> vals = (x = [1.0],);\n\njulia> getvalue(vals, @varname(x)) # same as `getindex`\n1-element Vector{Float64}:\n 1.0\n\njulia> getvalue(vals, @varname(x[1])) # different from `getindex`\n1.0\n\njulia> getvalue(vals, @varname(x[2]))\nERROR: x[2] was not found in the NamedTuple provided\n[...]\n\nFor AbstractDict:\n\njulia> vals = Dict(@varname(x) => [1.0]);\n\njulia> getvalue(vals, @varname(x)) # same as `getindex`\n1-element Vector{Float64}:\n 1.0\n\njulia> getvalue(vals, @varname(x[1])) # different from `getindex`\n1.0\n\njulia> getvalue(vals, @varname(x[2]))\nERROR: x[2] was not found in the dictionary provided\n[...]\n\nIn the AbstractDict case we can also have keys such as v[1]:\n\njulia> vals = Dict(@varname(x[1]) => [1.0,]);\n\njulia> getvalue(vals, @varname(x[1])) # same as `getindex`\n1-element Vector{Float64}:\n 1.0\n\njulia> getvalue(vals, @varname(x[1][1])) # different from `getindex`\n1.0\n\njulia> getvalue(vals, @varname(x[1][2]))\nERROR: x[1][2] was not found in the dictionary provided\n[...]\n\njulia> getvalue(vals, @varname(x[2][1]))\nERROR: x[2][1] was not found in the dictionary provided\n[...]\n\njulia> getvalue(vals, @varname(x))\nERROR: x was not found in the dictionary provided\n[...]\n\nDictionaries can present ambiguous cases where the same variable is specified twice at different levels. In such a situation, getvalue attempts to find an exact match, and if that fails it returns the value with the most specific key.\n\nnote: Note\nIt is the user's responsibility to avoid such cases by ensuring that the dictionary passed in does not contain the same value specified multiple times.\n\njulia> vals = Dict(@varname(x) => [[1.0]], @varname(x[1]) => [2.0]);\n\njulia> # Here, the `x[1]` key is not used because `x` is an exact match.\n       getvalue(vals, @varname(x))\n1-element Vector{Vector{Float64}}:\n [1.0]\n\njulia> # Likewise, the `x` key is not used because `x[1]` is an exact match.\n       getvalue(vals, @varname(x[1]))\n1-element Vector{Float64}:\n 2.0\n\njulia> # No exact match, so the most specific key, i.e. `x[1]`, is used.\n       getvalue(vals, @varname(x[1][1]))\n2.0\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.index_to_dict","page":"VarNames and optics","title":"AbstractPPL.index_to_dict","text":"index_to_dict(::Integer)\nindex_to_dict(::AbstractVector{Int})\nindex_to_dict(::UnitRange)\nindex_to_dict(::StepRange)\nindex_to_dict(::Colon)\nindex_to_dict(::ConcretizedSlice{T, Base.OneTo{I}}) where {T, I}\nindex_to_dict(::Tuple)\n\nConvert an index i to a dictionary representation.\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.dict_to_index","page":"VarNames and optics","title":"AbstractPPL.dict_to_index","text":"dict_to_index(dict)\ndict_to_index(symbol_val, dict)\n\nConvert a dictionary representation of an index dict to an index.\n\nUsers can extend the functionality of dict_to_index (and hence VarName de/serialisation) by extending this method along with index_to_dict. Specifically, suppose you have a custom index type MyIndexType and you want to be able to de/serialise a VarName containing this index type. You should then implement the following two methods:\n\nAbstractPPL.index_to_dict(i::MyModule.MyIndexType) should return a dictionary representation of the index i. This dictionary must contain the key \"type\", and the corresponding value must be a string that uniquely identifies the index type. Generally, it makes sense to use the name of the type (perhaps prefixed with module qualifiers) as this value to avoid clashes. The remainder of the dictionary can have any structure you like.\nNote that Base.Dict does not guarantee key order, so if you need to preserve key order for fidelity in serialisation, consider returning an OrderedCollections.OrderedDict instead.\nSuppose the value of index_to_dict(i)[\"type\"] is \"MyModule.MyIndexType\". You should then implement the corresponding method AbstractPPL.dict_to_index(::Val{Symbol(\"MyModule.MyIndexType\")}, dict), which should take the dictionary representation as the second argument and return the original MyIndexType object.\n\nTo see an example of this in action, you can look in the the AbstractPPL test suite, which contains a test for serialising OffsetArrays.\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.varname_to_string","page":"VarNames and optics","title":"AbstractPPL.varname_to_string","text":"varname_to_string(vn::VarName)\n\nConvert a VarName as a string, via an intermediate dictionary. This differs from string(vn) in that concretised slices are faithfully represented (rather than being pretty-printed as colons).\n\nFor VarNames which index into an array, this function will only work if the indices can be serialised. This is true for all standard Julia index types, but if you are using custom index types, you will need to implement the index_to_dict and dict_to_index methods for those types. See the documentation of dict_to_index for instructions on how to do this.\n\njulia> varname_to_string(@varname(x))\n\"{\\\"optic\\\":{\\\"type\\\":\\\"Iden\\\"},\\\"sym\\\":\\\"x\\\"}\"\n\njulia> varname_to_string(@varname(x.a))\n\"{\\\"optic\\\":{\\\"child\\\":{\\\"type\\\":\\\"Iden\\\"},\\\"field\\\":\\\"a\\\",\\\"type\\\":\\\"Property\\\"},\\\"sym\\\":\\\"x\\\"}\"\n\n\n\n\n\n","category":"function"},{"location":"varname/#AbstractPPL.string_to_varname","page":"VarNames and optics","title":"AbstractPPL.string_to_varname","text":"string_to_varname(str::AbstractString)\n\nConvert a string representation of a VarName back to a VarName. The string should have been generated by varname_to_string.\n\n\n\n\n\n","category":"function"},{"location":"#AbstractPPL.jl","page":"AbstractPPL.jl","title":"AbstractPPL.jl","text":"A lightweight package containing interfaces and associated APIs for modelling languages for probabilistic programming.","category":"section"}]
}
